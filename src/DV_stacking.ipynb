{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def model_pred(model, data, kagg, y, ykagg=np.array([]), params=None):\n",
    "    # data - весь трейн в пандасе/ нумпай массиве / csr матрице\n",
    "    # kagg - весь тест в пандасе/ нумпай массиве / csr матрице\n",
    "    # y - таргет для всего трейна в пандас сериес или нумпай массиве\n",
    "    # params - параметры (см. пример)\n",
    "    \n",
    "    if type(data).__name__=='DataFrame':\n",
    "        data = data.values\n",
    "    if type(kagg).__name__=='DataFrame':\n",
    "        kagg = kagg.values\n",
    "    if type(y).__name__=='Series' or type(y).__name__=='DataFrame':\n",
    "        y = y.values\n",
    "        \n",
    "    if model == 'fastfm' and type(data).__name__ != 'csr_matrix':\n",
    "        data = csr_matrix(data)\n",
    "        kagg = csr_matrix(kagg)\n",
    "    if model == 'fastfm':\n",
    "        y = y.replace(0,-1)\n",
    "        \n",
    "    scores=[]\n",
    "    #  prediction matrices\n",
    "    data_out = np.zeros((data.shape[0]))\n",
    "    kagg_out = np.zeros((kagg.shape[0]))\n",
    "    \n",
    "    n_splits = 5\n",
    "    iters_total = 2\n",
    "    ids = pd.read_csv('data/final/data_ids.csv',usecols=['graph_id'])\n",
    "    graph_ids_unique = ids.graph_id.unique() # array of unique graphs\n",
    "    \n",
    "    for iter_num in range(iters_total):\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "        for train_graphs, test_graphs  in kf.split(graph_ids_unique):\n",
    "            train_ind = ids[ids.graph_id.isin(graph_ids_unique[train_graphs])].index.values\n",
    "            test_ind  = ids[ids.graph_id.isin(graph_ids_unique[test_graphs ])].index.values\n",
    "            \n",
    "            if model=='xgb' or model=='lgb' or model=='nnet': # add validation set\n",
    "                kf_valid = KFold(n_splits=8, shuffle=True)\n",
    "                graph_ids_train = graph_ids_unique[train_graphs]\n",
    "                train_graphs, valid_graphs = list(kf_valid.split(graph_ids_train))[0]\n",
    "                train_ind = ids[ids.graph_id.isin(graph_ids_train[train_graphs])].index.values\n",
    "                valid_ind = ids[ids.graph_id.isin(graph_ids_train[valid_graphs])].index.values \n",
    "                \n",
    "            if model=='lgb':\n",
    "                fold_pred, kagg_pred = lgb_pred (params, data[train_ind], y[train_ind], \n",
    "                                                         data[valid_ind], y[valid_ind],\n",
    "                                                         data[test_ind], kagg)\n",
    "            elif model=='xgb':\n",
    "                fold_pred, kagg_pred = xgb_pred (params, data[train_ind], y[train_ind], \n",
    "                                                         data[valid_ind], y[valid_ind],\n",
    "                                                         data[test_ind], kagg)\n",
    "            elif model=='nnet':\n",
    "                fold_pred, kagg_pred = nnet_pred(params, data[train_ind], y[train_ind], \n",
    "                                                         data[valid_ind], y[valid_ind],\n",
    "                                                         data[test_ind], kagg)\n",
    "            elif model=='fastfm':\n",
    "                fold_pred, kagg_pred = fastfm_pred(params, data[train_ind], y[train_ind], data[test_ind], kagg)\n",
    "                \n",
    "            else:\n",
    "                model.fit(train, ytrain)\n",
    "                try:\n",
    "                    fold_pred = model.predict_proba(test)[:,1]\n",
    "                    kagg_pred = model.predict_proba(kagg)[:,1]\n",
    "                except:\n",
    "                    try:\n",
    "                        fold_pred = model.predict_proba(test)\n",
    "                        kagg_pred = model.predict_proba(kagg)\n",
    "                    except:\n",
    "                        fold_pred = model.predict(test)\n",
    "                        kagg_pred = model.predict(kagg)\n",
    "                    \n",
    "            data_out[test_ind] += fold_pred\n",
    "            kagg_out += kagg_pred\n",
    "            if iter_num==0:\n",
    "                #print (log_loss(ytest, fold_pred))\n",
    "                print (log_loss(y[test_ind], fold_pred))\n",
    "            \n",
    "        if ykagg.shape[0]>0:\n",
    "            print ('kagg score:', log_loss(ykagg, kagg_out/(iter_num+1)/n_splits))\n",
    "        print ('train score:', log_loss(y, data_out/(iter_num+1)))\n",
    "    data_out /= iters_total\n",
    "    kagg_out /= (iters_total*n_splits)\n",
    "    return data_out, kagg_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_2['lgb_oof'], test_2['lgb_oof'] = model_pred('lgb', \n",
    "                                                    train[num_features], \n",
    "                                                    test [num_features], \n",
    "                                                    ytrain, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мусор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "t1 = pd.read_csv('subs/lgb_oof_325_CV24265_WITH_correctSplits_pos_tags.csv',usecols=['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1['old'] = pd.read_csv('subs/lgb_oof_307_CV1771_WITH_feat236_stem_locs_tfidfoof_FMoof_lenfm_magicCorrected_NO_tfidf_FM_oofs.csv',usecols=['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_duplicate</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.98773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>0.98773</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              is_duplicate      old\n",
       "is_duplicate       1.00000  0.98773\n",
       "old                0.98773  1.00000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTrain = pd.read_csv(INPUT_FOLDER + '/train.csv', usecols=['is_duplicate']).values.ravel()\n",
    "\n",
    "ids = pd.read_csv('data/final/data_ids.csv',usecols=['graph_id'])\n",
    "graph_ids_unique = ids.graph_id.unique()\n",
    "\n",
    "with open('dump_sequences.pkl', 'rb') as f:\n",
    "    x1_train, x2_train, x1_test, x2_test, nb_words = pickle.load(f)\n",
    "embedding_matrix = np.load('embedding_matrix.npy')\n",
    "\n",
    "\n",
    "\n",
    "print x1_train.shape, x2_train.shape\n",
    "print x1_test.shape, x2_test.shape\n",
    "print nb_words\n",
    "\n",
    "N_FOLDS = 5\n",
    "N_ITER = 3\n",
    "\n",
    "print \"Creating train and test sets for blending.\"\n",
    "preds_train = np.zeros((x1_train.shape[0]))\n",
    "preds_test_j = np.zeros((x1_test.shape[0]))\n",
    "loglosses = []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "for iter_num in range(N_ITER):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    splits = list(kf.split(graph_ids_unique))\n",
    "\n",
    "    for fold_id, (train_graphs, test_graphs) in enumerate(splits):\n",
    "        print \"Fold\", fold_id\n",
    "        train_ind = ids[ids.graph_id.isin(graph_ids_unique[train_graphs])].index.values # temporary train indexes\n",
    "        test_ind  = ids[ids.graph_id.isin(graph_ids_unique[test_graphs ])].index.values # final test indexes\n",
    "        \n",
    "        kf_valid = KFold(n_splits=8)\n",
    "        graph_ids_train = graph_ids_unique[train_graphs]\n",
    "        train_graphs, valid_graphs = list(kf_valid.split(graph_ids_train))[0]\n",
    "        train_ind = ids[ids.graph_id.isin(graph_ids_train[train_graphs])].index.values # final train indexes\n",
    "        valid_ind = ids[ids.graph_id.isin(graph_ids_train[valid_graphs])].index.values # final valid indexes\n",
    "        \n",
    "\n",
    "        clf = KerasConvnet()\n",
    "        clf.fit(x1_train[train_ind], x2_train[train_ind], YTrain[train_ind],\n",
    "                x1_train[valid_ind], x2_train[valid_ind], YTrain[valid_ind])\n",
    "\n",
    "        y_pred = clf.predict(x1_train[test_ind], x2_train[test_ind])\n",
    "        preds_train[test_ind] += y_pred\n",
    "\n",
    "        lloss = log_loss(YTrain[test_ind], y_pred)\n",
    "        loglosses.append(lloss)\n",
    "        print 'LogLoss: ', lloss\n",
    "\n",
    "        # Predict on entire test set\n",
    "        preds_test_j += clf.predict(x1_test, x2_test).ravel()\n",
    "\n",
    "    print \"Out of fold logloss-es:\\n\", loglosses\n",
    "    print 'train score:', log_loss(YTrain, preds_train / (iter_num + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08537451907256936, 0.08620366919042675)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame()\n",
    "t['1313'] = pd.read_csv('subs/lgb_oof_324_CV1767_WITH_correctSplits_pos.csv', usecols=['is_duplicate'])\n",
    "t['12758'] = pd.read_csv('subs/lgb_oof_311_WITH_feat236_stem_locs_tfidfoof_FMoof_lenfm_magicCorrected_CV1746.csv', usecols=['is_duplicate'])\n",
    "t['1313'].mean(), t['12758'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3675672312058731, 0.3681929089369834)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame()\n",
    "t['1313'] = pd.read_csv('subs/data_lgb_oof_324_CV1767_WITH_correctSplits_pos.csv', usecols=['lgb_oof_324_CV1767_WITH_correctSplits_pos'])\n",
    "t['12758'] = pd.read_csv('subs/data_lgb_oof_311_WITH_feat236_stem_locs_tfidfoof_FMoof_lenfm_magicCorrected_CV1746.csv', usecols=['lgb_oof_311_WITH_feat236_stem_locs_tfidfoof_FMoof_lenfm_magicCorrected_CV1746'])\n",
    "t['1313'].mean(), t['12758'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = pd.read_csv('subs/kagg_lgb_oof_324_CV1767_WITH_correctSplits_pos.csv', usecols=['is_duplicate'])\n",
    "t['12755'] = pd.read_csv('subs/kagg_lgb_oof_325_CV24265_WITH_correctSplits_pos_tags.csv', usecols=['is_duplicate'])\n",
    "t['12758'] = pd.read_csv('subs/kagg_lgb_oof_311_WITH_feat236_stem_locs_tfidfoof_FMoof_lenfm_magicCorrected_CV1746.csv', usecols=['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = pd.DataFrame()\n",
    "t['new'] = pd.read_csv('subs/lgb_oof_324_CV1759_WITH_correctSplits_pos.csv', usecols=['is_duplicate'])\n",
    "t['1313'] = pd.read_csv('subs/lgb_oof_324_CV1767_WITH_correctSplits_pos.csv', usecols=['is_duplicate'])\n",
    "t['12755'] = pd.read_csv('subs/lgb_oof_325_CV24265_WITH_correctSplits_pos_tags.csv', usecols=['is_duplicate'])\n",
    "t['12758'] = pd.read_csv('subs/lgb_oof_311_WITH_feat236_stem_locs_tfidfoof_FMoof_lenfm_magicCorrected_CV1746.csv', usecols=['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new</th>\n",
       "      <th>1313</th>\n",
       "      <th>12755</th>\n",
       "      <th>12758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996915</td>\n",
       "      <td>0.997896</td>\n",
       "      <td>0.997806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>0.996915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997647</td>\n",
       "      <td>0.997114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12755</th>\n",
       "      <td>0.997896</td>\n",
       "      <td>0.997647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12758</th>\n",
       "      <td>0.997806</td>\n",
       "      <td>0.997114</td>\n",
       "      <td>0.998115</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            new      1313     12755     12758\n",
       "new    1.000000  0.996915  0.997896  0.997806\n",
       "1313   0.996915  1.000000  0.997647  0.997114\n",
       "12755  0.997896  0.997647  1.000000  0.998115\n",
       "12758  0.997806  0.997114  0.998115  1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEFCAYAAAAYKqc0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1KBDHdJKpDhLkkFMtwlqUD/D5ILBTNlEuzLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f529d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(t['1313'], kde=False)\n",
    "sns.distplot(t ['new'], kde=False)\n",
    "sns.distplot(t ['12758'], kde=False)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked',)).History will not be written to the database.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%pylab inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "\n",
    "from scipy.sparse import csr_matrix, coo_matrix,hstack, vstack\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "import multiprocessing as mp\n",
    "NUM_CORES = 4\n",
    "def apply_parallel(df, my_func):\n",
    "    df_splitted = np.array_split(df, NUM_CORES)\n",
    "    pool = mp.Pool(NUM_CORES)\n",
    "    result = pd.concat(pool.map(my_func, df_splitted))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  4  6  7  8  9 10 11 12 15 16 17 18 19]\n",
      "[  3  13  28  29  31  54  59  71  76  78  88  93  94 100 103]\n",
      "[ 1  5 14 24 26 27 38 39 40 43 49 51 53 58 67]\n",
      "\n",
      "[ 2  4  5  6  7  8 10 11 12 13 14 15 17 19 20]\n",
      "[ 1  3 18 23 27 29 37 49 63 64 67 71 75 95 96]\n",
      "[ 0  9 16 22 25 28 31 34 35 44 50 52 55 56 59]\n",
      "\n",
      "[ 0  1  2  4  5  6  7  8  9 10 12 13 14 16 17]\n",
      "[ 31  59  68  78 115 120 122 125 136 137 142 143 158 159 165]\n",
      "[ 3 11 15 23 29 30 41 42 45 46 48 73 75 82 85]\n",
      "\n",
      "[ 0  1  3  5  7  8  9 11 13 16 19 20 21 22 23]\n",
      "[ 14  15  28  44  45  51  59  63  81  90  92  94  96 101 103]\n",
      "[ 2  4  6 10 12 17 18 47 64 65 66 71 72 76 77]\n",
      "\n",
      "[ 0  1  2  3  4  5  6  9 10 11 12 14 15 16 17]\n",
      "[ 23  24  26  30  38  42  52  58  59  60  64  65  67 107 111]\n",
      "[ 7  8 13 19 20 21 32 33 36 37 54 57 61 63 74]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_splits = 5\n",
    "iters_total = 1\n",
    "ids = pd.read_csv('data/final/data_ids.csv',usecols=['graph_id'])\n",
    "graph_ids_unique = ids.graph_id.unique()\n",
    "    \n",
    "for iter_num in range(iters_total):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    for train_graphs, test_graphs  in kf.split(graph_ids_unique):\n",
    "        train_ind = ids[ids.graph_id.isin(graph_ids_unique[train_graphs])].index.values\n",
    "        test_ind  = ids[ids.graph_id.isin(graph_ids_unique[test_graphs ])].index.values\n",
    "            \n",
    "        if True: # add validation set\n",
    "            kf_valid = KFold(n_splits=7, shuffle=True)\n",
    "            graph_ids_train = graph_ids_unique[train_graphs]\n",
    "            train_graphs, valid_graphs = list(kf_valid.split(graph_ids_train))[0]\n",
    "            train_ind = ids[ids.graph_id.isin(graph_ids_train[train_graphs])].index.values\n",
    "            valid_ind = ids[ids.graph_id.isin(graph_ids_train[valid_graphs])].index.values\n",
    "        print (train_ind[:15])\n",
    "        print (valid_ind[:15])\n",
    "        print (test_ind[:15])\n",
    "        print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gtrain = ids.iloc[train_ind].graph_id.unique()\n",
    "gvalid = ids.iloc[valid_ind].graph_id.unique()\n",
    "gtest = ids.iloc[test_ind].graph_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,      3,      5, ..., 535856, 535862, 535864])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    47,     49,     53, ..., 535815, 535836, 535868])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
